{"cells":[{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import ReduceLROnPlateau\n","execution_count":2,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"def get_data_train(filename):\n    with open(filename) as training_file:\n        file = csv.reader(training_file, delimiter = \",\")\n        images = []\n        labels = []\n        ignore = 1\n        for row in file:\n            if ignore == 1:\n                ignore = 0\n                continue\n            labels.append(row[0])\n            images.append(np.array_split(row[1:],28))\n    return np.array(images).astype(\"int32\"), np.array(labels).astype(\"int32\")","execution_count":3,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"def get_data_test(filename):\n    with open(filename) as training_file:\n        file = csv.reader(training_file, delimiter = \",\")\n        images = []\n        ignore = 1\n        for row in file:\n            if ignore == 1:\n                ignore = 0\n                continue\n            images.append(np.array_split(row,28))\n    return np.array(images).astype(\"int32\")","execution_count":4,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"\ntrain_path = '/kaggle/input/digit-recognizer/train.csv'\ntest_path = '/kaggle/input/digit-recognizer/test.csv'\n\ntrain_images, train_labels = get_data_train(train_path)\ntest_images = get_data_test(test_path)\n","execution_count":5,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n      rotation_range=15,\n      width_shift_range=0.1,\n      height_shift_range=0.1,\n      shear_range=0.1,\n      zoom_range=0.1,\n      horizontal_flip=False,\n      fill_mode='nearest'\n    )","execution_count":6,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"#final model\nfinal_model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (5,5), activation=tf.nn.relu,padding='Same',input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu,padding = 'Same'),\n    tf.keras.layers.MaxPooling2D(2,2),\n\n    tf.keras.layers.Flatten(),\n\n    tf.keras.layers.Dense(128,activation=tf.nn.relu),\n    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n])\n\nfinal_model.compile(loss = 'categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(), metrics=['acc'])\n\nfinal_model.summary()\n\ntrain_labels_cat = to_categorical(train_labels)\ntrain_images = np.expand_dims(train_images, axis=3)\ntest_images = test_images/255.0\n\nlearning_rate_reduction_final = ReduceLROnPlateau(monitor='acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.000003)\n\n\nhistory = final_model.fit(train_datagen.flow(train_images, train_labels_cat, batch_size=64),\n                    epochs = 30,\n                    verbose = 1,\n                   callbacks=[learning_rate_reduction_final])\n","execution_count":7,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 28, 28, 64)        1664      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 14, 14, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 6272)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               802944    \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 879,754\nTrainable params: 879,754\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/30\n657/657 [==============================] - 16s 24ms/step - loss: 0.2755 - acc: 0.9140 - lr: 0.0010\nEpoch 2/30\n657/657 [==============================] - 16s 24ms/step - loss: 0.0884 - acc: 0.9718 - lr: 0.0010\nEpoch 3/30\n657/657 [==============================] - 17s 26ms/step - loss: 0.0652 - acc: 0.9796 - lr: 0.0010\nEpoch 4/30\n657/657 [==============================] - 15s 23ms/step - loss: 0.0558 - acc: 0.9825 - lr: 0.0010\nEpoch 5/30\n657/657 [==============================] - 15s 24ms/step - loss: 0.0488 - acc: 0.9848 - lr: 0.0010\nEpoch 6/30\n657/657 [==============================] - 15s 22ms/step - loss: 0.0428 - acc: 0.9865 - lr: 0.0010\nEpoch 7/30\n657/657 [==============================] - 16s 25ms/step - loss: 0.0379 - acc: 0.9886 - lr: 0.0010\nEpoch 8/30\n657/657 [==============================] - 15s 22ms/step - loss: 0.0364 - acc: 0.9883 - lr: 0.0010\nEpoch 9/30\n657/657 [==============================] - 15s 23ms/step - loss: 0.0329 - acc: 0.9895 - lr: 0.0010\nEpoch 10/30\n657/657 [==============================] - 15s 23ms/step - loss: 0.0325 - acc: 0.9899 - lr: 0.0010\nEpoch 11/30\n657/657 [==============================] - 16s 24ms/step - loss: 0.0293 - acc: 0.9909 - lr: 0.0010\nEpoch 12/30\n657/657 [==============================] - 15s 23ms/step - loss: 0.0272 - acc: 0.9914 - lr: 0.0010\nEpoch 13/30\n657/657 [==============================] - 15s 22ms/step - loss: 0.0265 - acc: 0.9916 - lr: 0.0010\nEpoch 14/30\n657/657 [==============================] - 15s 22ms/step - loss: 0.0253 - acc: 0.9917 - lr: 0.0010\nEpoch 15/30\n657/657 [==============================] - 16s 24ms/step - loss: 0.0248 - acc: 0.9923 - lr: 0.0010\nEpoch 16/30\n657/657 [==============================] - 14s 22ms/step - loss: 0.0218 - acc: 0.9931 - lr: 0.0010\nEpoch 17/30\n657/657 [==============================] - 15s 22ms/step - loss: 0.0227 - acc: 0.9928 - lr: 0.0010\nEpoch 18/30\n657/657 [==============================] - 15s 23ms/step - loss: 0.0209 - acc: 0.9934 - lr: 0.0010\nEpoch 19/30\n657/657 [==============================] - 16s 24ms/step - loss: 0.0205 - acc: 0.9937 - lr: 0.0010\nEpoch 20/30\n657/657 [==============================] - 15s 22ms/step - loss: 0.0208 - acc: 0.9936 - lr: 0.0010\nEpoch 21/30\n655/657 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9937\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n657/657 [==============================] - 15s 23ms/step - loss: 0.0206 - acc: 0.9936 - lr: 0.0010\nEpoch 22/30\n657/657 [==============================] - 14s 22ms/step - loss: 0.0131 - acc: 0.9958 - lr: 5.0000e-04\nEpoch 23/30\n657/657 [==============================] - 16s 24ms/step - loss: 0.0116 - acc: 0.9967 - lr: 5.0000e-04\nEpoch 24/30\n657/657 [==============================] - 14s 22ms/step - loss: 0.0128 - acc: 0.9960 - lr: 5.0000e-04\nEpoch 25/30\n656/657 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9959\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n657/657 [==============================] - 14s 22ms/step - loss: 0.0127 - acc: 0.9960 - lr: 5.0000e-04\nEpoch 26/30\n657/657 [==============================] - 15s 23ms/step - loss: 0.0092 - acc: 0.9971 - lr: 2.5000e-04\nEpoch 27/30\n657/657 [==============================] - 15s 23ms/step - loss: 0.0081 - acc: 0.9972 - lr: 2.5000e-04\nEpoch 28/30\n657/657 [==============================] - 15s 23ms/step - loss: 0.0074 - acc: 0.9976 - lr: 2.5000e-04\nEpoch 29/30\n657/657 [==============================] - 15s 22ms/step - loss: 0.0080 - acc: 0.9970 - lr: 2.5000e-04\nEpoch 30/30\n657/657 [==============================] - 15s 22ms/step - loss: 0.0072 - acc: 0.9979 - lr: 2.5000e-04\n","name":"stdout"}]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"%matplotlib inline\nacc = history.history['acc']\nloss = history.history['loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.title('Training accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","execution_count":8,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'val_acc'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-291a93e8b7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'val_acc'"]}]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"test_images = np.expand_dims(test_images, axis=3)\n\nresults = final_model.predict(test_images)\n\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\n\nprint(results.shape)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"get_ipython().run_cell_magic('javascript', '', '<!-- Save the notebook -->\\nIPython.notebook.save_checkpoint();')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}